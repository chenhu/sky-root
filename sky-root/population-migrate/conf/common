#!/usr/bin/env bash
# 全省数据od分析参数设置
export param='--master yarn-client --queue root.bdoc.renter_1.renter_17.dev_51 --num-executors 12  --executor-cores 6 --driver-memory 8G --executor-memory 80G --conf "spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC" --conf spark.default.parallelism=300 --conf spark.driver.maxResultSize=2048m --conf spark.kryoserializer.buffer.max=256m --conf spark.kryoserializer.buffer=64m  --conf spark.executor.heartbeatInterval=10000000 --conf spark.network.timeout=10000001 --class com.sky.signal.pre.Application '$app'' 
#export param='--master yarn-client --queue root.bdoc.renter_1.renter_17.dev_51 --num-executors 10  --executor-cores 20 --driver-memory 8G --executor-memory 80G --conf "spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC" --conf spark.default.parallelism=300 --conf spark.driver.maxResultSize=2048m --conf spark.kryoserializer.buffer.max=256m --conf spark.kryoserializer.buffer=64m  --conf spark.executor.heartbeatInterval=10000000 --conf spark.network.timeout=10000001 --class com.sky.signal.pre.Application '$app'' 
#export param='--master yarn-client --queue root.bdoc.renter_1.renter_17.dev_51 --num-executors 20  --executor-cores 20 --driver-memory 8G --executor-memory 50G --conf "spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC" --conf spark.default.parallelism=1200 --conf spark.driver.maxResultSize=2048m --conf spark.kryoserializer.buffer.max=256m --conf spark.kryoserializer.buffer=64m  --conf spark.executor.heartbeatInterval=10000000 --conf spark.network.timeout=10000001 --class com.sky.signal.pre.Application '$app''

